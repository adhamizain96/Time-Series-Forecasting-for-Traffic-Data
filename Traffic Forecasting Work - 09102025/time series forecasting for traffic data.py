# -*- coding: utf-8 -*-
"""Time Series Forecasting for Traffic Data - 09102025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kue6SDt1wxzxaQvcbZUhdK5AKpPibILR
"""

#Import the necessary libraries
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import random

#Create a sample DF - Datetime, Lane, Direction, Class, Rate, Volume, and Revenue
np.random.seed(42)

start_date = datetime(2023, 1, 1)
end_date = datetime(2025, 9, 10)
date_range = pd.date_range(start=start_date, end=end_date, freq='h')

lanes = [f"Lane_{i}" for i in range(1, 23)]
lane_directions = {f"Lane_{i}": "Eastbound" if i <= 11 else "Westbound" for i in range(1, 23)}

vehicle_classes = [2, 3, 4, 5, 6, 7]
weather_conditions = ['Clear', 'Cloudy', 'Rainy', 'Foggy', 'Snowing']

def get_toll_rate(vehicle_class, hour):
    peak = 4 <= hour < 20
    if vehicle_class == 2:
        return 7.80
    elif vehicle_class == 3:
        return 27.20 if peak else 19.50
    elif vehicle_class == 4:
        return 36.30 if peak else 25.90
    elif vehicle_class == 5:
        return 45.40 if peak else 32.40
    elif vehicle_class == 6:
        return 54.40 if peak else 38.90
    else:
        return 63.50 if peak else 45.40

data = []
for dt in date_range:
    for lane in lanes:
        direction = lane_directions[lane]
        for vehicle_class in vehicle_classes:
            volume = np.random.poisson(lam=5 if 4 <= dt.hour < 20 else 2)
            toll_rate = get_toll_rate(vehicle_class, dt.hour)
            revenue = volume * toll_rate
            weather = random.choices(weather_conditions, weights=[50, 20, 15, 10, 5])[0]
            data.append({
                'Datetime': dt,
                'Lane': lane,
                'Direction': direction,
                'VehicleClass': vehicle_class,
                'TollRate': toll_rate,
                'Volume': volume,
                'Weather': weather,
                'Revenue': revenue,
                'DayOfWeek': dt.strftime('%A'),
                'Hour': dt.hour
            })

df = pd.DataFrame(data)

df.head()

#This is the total number of rows in the sample df. This should be a good enough number to run exploratory analysis from.
print(f"There are {df.shape[0]} rows of data in the dataframe.")

#Aggregate the df by Day - Look at Volume & Revenue Columns
daily_df = (
    df.groupby(df["Datetime"].dt.date)[["Volume", "Revenue"]]
    .sum()
    .reset_index()
    .rename(columns={"Datetime": "Date"})
)

#print("Daily shape:", daily_df.shape)

daily_df.head()

#Daily Traffic Volume (Weekday vs. Weekend)

#Add a DayOfWeek/IsWeekend columns
daily_df["Date"] = pd.to_datetime(daily_df["Date"])
daily_df["DayOfWeek"] = daily_df["Date"].dt.day_name()
daily_df["IsWeekend"] = daily_df["DayOfWeek"].isin(["Saturday", "Sunday"])

#daily_df.head()

#Model that will be used for Analysis: XGBOOST
#Note: This was previosuly decided in the initial workbook

import warnings

#Ignore all DeprecationWarnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

#Import the necessary libraries
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

df_ml = daily_df.copy()
#df_ml.head()

#Lag Features
df_ml["lag1"] = df_ml["Volume"].shift(1)
df_ml["lag2"] = df_ml["Volume"].shift(2)
df_ml["lag7"] = df_ml["Volume"].shift(7)

#Rolling Features
df_ml["roll3"] = df_ml["Volume"].shift(1).rolling(3).mean()
df_ml["roll7"] = df_ml["Volume"].shift(1).rolling(7).mean()

#Drop the null values
df_ml = df_ml.dropna()
#df_ml.head()

#Features/Target
X = df_ml[["lag1", "lag2", "lag7", "roll3", "roll7", "IsWeekend"]]
y = df_ml["Volume"]

#Train-Test Split
X_train, X_test, y_train, y_test = X.iloc[:-7], X.iloc[-7:], y.iloc[:-7], y.iloc[-7:]

#XGBoost Model
model = xgb.XGBRegressor(
    n_estimators=500,
    learning_rate=0.05,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

#Import the necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#Future 21 Days
HORIZON = 21

#last_date = last_date = daily_df.index.max()
last_date = daily_df["Date"].max()
future_dates = pd.date_range(last_date + pd.Timedelta(days=1), periods=HORIZON, freq="D")

vol_series = daily_df["Volume"].copy()

future_rows = []

for dt in future_dates:
    lag1 = vol_series.iloc[-1]
    lag2 = vol_series.iloc[-2]
    lag7 = vol_series.iloc[-7]
    roll3 = vol_series.iloc[-3:].mean()
    roll7 = vol_series.iloc[-7:].mean()
    is_weekend = pd.Timestamp(dt).day_name() in ["Saturday", "Sunday"]

    X_next = pd.DataFrame([{
        "lag1": lag1, "lag2": lag2, "lag7": lag7,
        "roll3": roll3, "roll7": roll7,
        "IsWeekend": is_weekend
    }], index=[dt])

    y_hat = float(model.predict(X_next))

    vol_series.loc[dt] = y_hat

    future_rows.append({
        "Date": dt,
        "Forecast_Volume": y_hat
    })

xgb_future_df = pd.DataFrame(future_rows).set_index("Date").round(3)

#xgb_future_df
#xgb_future_df.head()

#Past 21 Days
lookback = 21

if "Date" in daily_df.columns:
    daily_idx = daily_df.copy()
    daily_idx["Date"] = pd.to_datetime(daily_idx["Date"])
    daily_idx = daily_idx.set_index("Date")
else:
    daily_idx = daily_df.copy()
    daily_idx.index = pd.to_datetime(daily_idx.index)

actual_tail = (
    daily_idx[["Volume"]]
    .iloc[-lookback:]
    .rename(columns={"Volume": "Actual_Volume"})
)

xgb_future_df = xgb_future_df.copy()
xgb_future_df.index = pd.to_datetime(xgb_future_df.index)

plot_df = actual_tail.join(xgb_future_df, how="outer")
#plot_df

#Create a Plot of the Data
plt.figure(figsize=(12, 5))
plt.plot(
    plot_df.index,
    plot_df["Actual_Volume"],
    label="Actual Volume (previous 3 weeks)",
    color="green",
    marker="o"
    )
plt.plot(
    plot_df.index,
    plot_df["Forecast_Volume"],
    label="Forecasted Volume (next 3 weeks)",
    color="red",
    marker="s"
    )
plt.title("XGBoost Multi-Step Forecast (Daily Volume)")
plt.xlabel("Date")
plt.ylabel("Traffic Volume")
plt.grid()
plt.legend()

plt.show()

#Q: Evaluate the changes in Toll Rate and how it would affect Traffic Volume & Revenue
#Note: In reality, I need "ACTUAL TRAFFIC DATA" for a "MORE ACCURATE REPRESENTATION"

#Aggregate the df by Day - Look at Volume & Revenue Columns
daily_df = (
    df.groupby(df["Datetime"].dt.date)[["Volume", "Revenue", "TollRate"]]
    #.sum()
    #.reset_index()
    .agg({"Volume": "sum", "Revenue": "sum", "TollRate": "mean"})
    .reset_index()
    .rename(columns={"Datetime": "Date"})
)

#print("Daily shape:", daily_df.shape)

daily_df.head()

#Daily Traffic Volume (Weekday vs. Weekend)

#Add a DayOfWeek/IsWeekend columns
daily_df["Date"] = pd.to_datetime(daily_df["Date"])
daily_df["DayOfWeek"] = daily_df["Date"].dt.day_name()
daily_df["IsWeekend"] = daily_df["DayOfWeek"].isin(["Saturday", "Sunday"])

daily_df.head()

#Retrain XGBoost Model with Daily TollRate Column Added

#Distinct VehicleClass/TollRate Combinations
#Link: https://www.chicagoskyway.org/toll-information/
vc_tr_combinations = df[['VehicleClass', 'TollRate']].drop_duplicates()
vc_tr_combinations.sort_values(by='VehicleClass', inplace=True)
vc_tr_combinations

#Note: Add Evaluation Metrics to see if the XGBoost model under/or outperforms the baseline

#Import the necessary libraries
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

#MAE, RMSE/SMAPE Metrics
mae = mean_absolute_error(y_test, y_pred)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

epsilon = 1e-10
smape = 100 * np.mean(2 * np.abs(y_pred - y_test) / (np.abs(y_test) + np.abs(y_pred) + epsilon))

print("XGBoost Model:")
print(f"MAE (Mean Absolute Error): {mae:.2f}")
print(f"RMSE (Root Mean Squared Error):{rmse:.2f}")
print(f"sMAPE (Symmetric Mean Absolute Percentage Error): {smape:.2f}%")

# Seasonal Naive Baseline (lag-7)
y_naive = X_test['lag7'].values

mae_naive = mean_absolute_error(y_test, y_naive)
mse_naive = mean_squared_error(y_test, y_naive)
rmse_naive = np.sqrt(mse_naive)

epsilon = 1e-10
smape_naive = 100 * np.mean(2 * np.abs(y_naive - y_test) / (np.abs(y_test) + np.abs(y_naive) + epsilon))

print("Seasonal Naive Baseline (Lag-7) Model:")
print(f"MAE (Mean Absolute Error): {mae_naive:.2f}")
print(f"RMSE (Root Mean Squared Error):{rmse_naive:.2f}")
print(f"sMAPE (Symmetric Mean Absolute Percentage Error): {smape_naive:.2f}%")

#Note: Need to improve the Model
#Idea 1: Swap TollRate w/ AvgTollPaid

daily_df = (
    df.groupby(df["Datetime"].dt.date)[["Volume", "Revenue", "TollRate"]]
      .agg({"Volume": "sum", "Revenue": "sum"})
      .reset_index()
      .rename(columns={"Datetime": "Date"})
)

daily_df["Date"] = pd.to_datetime(daily_df["Date"])
#AvgTollPaid
daily_df["AvgTollPaid"] = daily_df["Revenue"] / daily_df["Volume"]

daily_df["DayOfWeek"] = daily_df["Date"].dt.day_name()
daily_df["IsWeekend"] = daily_df["DayOfWeek"].isin(["Saturday", "Sunday"])

daily_df.head()

df_ml = daily_df.copy()
#df_ml.head()

#Lag Features
df_ml["lag1"] = df_ml["Volume"].shift(1)
df_ml["lag2"] = df_ml["Volume"].shift(2)
df_ml["lag7"] = df_ml["Volume"].shift(7)

#Rolling Features
df_ml["roll3"] = df_ml["Volume"].shift(1).rolling(3).mean()
df_ml["roll7"] = df_ml["Volume"].shift(1).rolling(7).mean()

#Drop the null values
df_ml = df_ml.dropna()
#df_ml.head()

#Features/Target
X = df_ml[["lag1", "lag2", "lag7", "roll3", "roll7", "IsWeekend", "AvgTollPaid"]]
y = df_ml["Volume"]

#Train-Test Split
X_train, X_test, y_train, y_test = X.iloc[:-7], X.iloc[-7:], y.iloc[:-7], y.iloc[-7:]

#XGBoost Model
model = xgb.XGBRegressor(
    n_estimators=500,
    learning_rate=0.05,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

#Import the necessary libraries
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

#MAE, RMSE/SMAPE Metrics
mae = mean_absolute_error(y_test, y_pred)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

epsilon = 1e-10
smape = 100 * np.mean(2 * np.abs(y_pred - y_test) / (np.abs(y_test) + np.abs(y_pred) + epsilon))

print("XGBoost Model:")
print(f"MAE (Mean Absolute Error): {mae:.2f}")
print(f"RMSE (Root Mean Squared Error):{rmse:.2f}")
print(f"sMAPE (Symmetric Mean Absolute Percentage Error): {smape:.2f}%")

# Seasonal Naive Baseline (lag-7)
y_naive = X_test['lag7'].values

mae_naive = mean_absolute_error(y_test, y_naive)
mse_naive = mean_squared_error(y_test, y_naive)
rmse_naive = np.sqrt(mse_naive)

epsilon = 1e-10
smape_naive = 100 * np.mean(2 * np.abs(y_naive - y_test) / (np.abs(y_test) + np.abs(y_naive) + epsilon))

print("Seasonal Naive Baseline (Lag-7) Model:")
print(f"MAE (Mean Absolute Error): {mae_naive:.2f}")
print(f"RMSE (Root Mean Squared Error):{rmse_naive:.2f}")
print(f"sMAPE (Symmetric Mean Absolute Percentage Error): {smape_naive:.2f}%")

#Idea 2: Longer Trend Features/Evaluating Across Multiple Weeks

df_ml = daily_df.copy()

df_ml["lag1"] = df_ml["Volume"].shift(1)
df_ml["lag2"] = df_ml["Volume"].shift(2)
df_ml["lag7"] = df_ml["Volume"].shift(7)

df_ml["roll3"]  = df_ml["Volume"].shift(1).rolling(3).mean()
df_ml["roll7"]  = df_ml["Volume"].shift(1).rolling(7).mean()
df_ml["roll14"] = df_ml["Volume"].shift(1).rolling(14).mean()
df_ml["roll30"] = df_ml["Volume"].shift(1).rolling(30).mean()

#Drop the null values
df_ml = df_ml.dropna()
#df_ml.head()

#Features/Target
X = df_ml[["lag1","lag2","lag7","roll3","roll7","roll14","roll30","IsWeekend","AvgTollPaid"]]
y = df_ml["Volume"]

#Train-Test Split
X_train, X_test, y_train, y_test = X.iloc[:-7], X.iloc[-7:], y.iloc[:-7], y.iloc[-7:]

#XGBoost Model
model = xgb.XGBRegressor(
    n_estimators=500,
    learning_rate=0.05,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

#Import the necessary libraries
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

#MAE, RMSE/SMAPE Metrics
mae = mean_absolute_error(y_test, y_pred)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

epsilon = 1e-10
smape = 100 * np.mean(2 * np.abs(y_pred - y_test) / (np.abs(y_test) + np.abs(y_pred) + epsilon))

print("XGBoost Model:")
print(f"MAE (Mean Absolute Error): {mae:.2f}")
print(f"RMSE (Root Mean Squared Error):{rmse:.2f}")
print(f"sMAPE (Symmetric Mean Absolute Percentage Error): {smape:.2f}%")

# Seasonal Naive Baseline (lag-7)
y_naive = X_test['lag7'].values

mae_naive = mean_absolute_error(y_test, y_naive)
mse_naive = mean_squared_error(y_test, y_naive)
rmse_naive = np.sqrt(mse_naive)

epsilon = 1e-10
smape_naive = 100 * np.mean(2 * np.abs(y_naive - y_test) / (np.abs(y_test) + np.abs(y_naive) + epsilon))

print("Seasonal Naive Baseline (Lag-7) Model:")
print(f"MAE (Mean Absolute Error): {mae_naive:.2f}")
print(f"RMSE (Root Mean Squared Error):{rmse_naive:.2f}")
print(f"sMAPE (Symmetric Mean Absolute Percentage Error): {smape_naive:.2f}%")

#TDL: I need to make the model more accurate. In the meantime, let's see what Toll Rate Change does to the calculations (Volume/Revenue?

def forecast_toll_scenario(model, df, vehicle_class=2, change_pct=0.10, horizon=7):
    df_adj = df.copy()
    mask = df_adj["VehicleClass"] == vehicle_class
    df_adj.loc[mask, "TollRate"] *= (1 + change_pct)
    df_adj["Revenue"] = df_adj["Volume"] * df_adj["TollRate"]

    daily_adj = (
        df_adj.groupby(df_adj["Datetime"].dt.date)[["Volume", "Revenue"]].sum().reset_index()
    )
    daily_adj = daily_adj.rename(columns={"Datetime": "Date"})
    daily_adj["Date"] = pd.to_datetime(daily_adj["Date"])
    daily_adj["AvgTollPaid"] = daily_adj["Revenue"] / daily_adj["Volume"]
    daily_adj["DayOfWeek"] = daily_adj["Date"].dt.day_name()
    daily_adj["IsWeekend"] = daily_adj["DayOfWeek"].isin(["Saturday", "Sunday"])

    df_ml = daily_adj.copy()
    df_ml["lag1"] = df_ml["Volume"].shift(1)
    df_ml["lag2"] = df_ml["Volume"].shift(2)
    df_ml["lag7"] = df_ml["Volume"].shift(7)
    df_ml["roll3"] = df_ml["Volume"].shift(1).rolling(3).mean()
    df_ml["roll7"] = df_ml["Volume"].shift(1).rolling(7).mean()
    df_ml["roll14"] = df_ml["Volume"].shift(1).rolling(14).mean()
    df_ml["roll30"] = df_ml["Volume"].shift(1).rolling(30).mean()
    df_ml = df_ml.dropna().reset_index(drop=True)

    feature_cols = ["lag1","lag2","lag7","roll3","roll7","roll14","roll30","IsWeekend","AvgTollPaid"]
    X_adj = df_ml[feature_cols]
    y_pred = model.predict(X_adj.tail(horizon))

    orig_last = daily_df.tail(horizon).reset_index(drop=True)
    new_last  = daily_adj.tail(horizon).reset_index(drop=True)

    results = pd.DataFrame({
        "Date": orig_last["Date"],
        "Prev_Volume": orig_last["Volume"],
        "Prev_Revenue": orig_last["Revenue"],
        "New_Volume": y_pred,
        "New_Revenue": y_pred * new_last["AvgTollPaid"],
        "Diff_Volume": y_pred - orig_last["Volume"],
        "Diff_Revenue": (y_pred * new_last["AvgTollPaid"]) - orig_last["Revenue"]
    })

    return results

scenario_results = forecast_toll_scenario(model, df, vehicle_class=2, change_pct=0.2, horizon=60)
#scenario_results

#Drop the last row of data
scenario_results = scenario_results.iloc[:-1]

#Find the Percent Change in Volume and Revenue

total_prev_vol = scenario_results["Prev_Volume"].sum()
total_new_vol  = scenario_results["New_Volume"].sum()
total_prev_rev = scenario_results["Prev_Revenue"].sum()
total_new_rev  = scenario_results["New_Revenue"].sum()

total_vol_change = total_new_vol - total_prev_vol
total_rev_change = total_new_rev - total_prev_rev

pct_vol_change = (total_vol_change / total_prev_vol) * 100
pct_rev_change = (total_rev_change / total_prev_rev) * 100

summary = pd.DataFrame({
    "Total Prev. Vol.": [round(total_prev_vol, 2)],
    "Total New Vol.": [round(total_new_vol, 2)],
    "Total Change in Vol.": [round(total_vol_change, 2)],
    "% Vol. Change": [f"{round(pct_vol_change, 2)}%"],
    "Total Prev. Rev.": [round(total_prev_rev, 2)],
    "Total New Rev.": [round(total_new_rev, 2)],
    "Total Change in Rev.": [round(total_rev_change, 2)],
    "% Rev. Change": [f"{round(pct_rev_change, 2)}%"]
})

summary

#Note: The Volume/Revenue Change is not drastic enough on outliers.
#Idea 1: Retrain the XGBOOST Model

def augment_with_toll_variation(daily_df, toll_changes=[-0.3, -0.2, -0.1, 0.1, 0.2, 0.3], elasticity=-0.3):
    augmented = []
    for change in toll_changes:
        df_copy = daily_df.copy()
        df_copy["AvgTollPaid"] = df_copy["AvgTollPaid"] * (1 + change)
        df_copy["Volume"] = df_copy["Volume"] * (1 + elasticity * change)
        df_copy["Revenue"] = df_copy["Volume"] * df_copy["AvgTollPaid"]
        augmented.append(df_copy)
    augmented_df = pd.concat([daily_df] + augmented, axis=0).reset_index(drop=True)
    return augmented_df

augmented_daily_df = augment_with_toll_variation(daily_df)
augmented_daily_df.head()

min_max_df = augmented_daily_df.groupby("Date")["AvgTollPaid"].agg(["min","max"])
min_max_df.head()

df_ml = augmented_daily_df.copy()
df_ml["lag1"] = df_ml["Volume"].shift(1)
df_ml["lag2"] = df_ml["Volume"].shift(2)
df_ml["lag7"] = df_ml["Volume"].shift(7)
df_ml["roll3"] = df_ml["Volume"].shift(1).rolling(3).mean()
df_ml["roll7"] = df_ml["Volume"].shift(1).rolling(7).mean()
df_ml["roll14"] = df_ml["Volume"].shift(1).rolling(14).mean()
df_ml["roll30"] = df_ml["Volume"].shift(1).rolling(30).mean()
df_ml = df_ml.dropna().reset_index(drop=True)

feature_cols = ["lag1","lag2","lag7","roll3","roll7","roll14","roll30","IsWeekend","AvgTollPaid"]
X = df_ml[feature_cols]
y = df_ml["Volume"]

X_train, X_test, y_train, y_test = X.iloc[:-30], X.iloc[-30:], y.iloc[:-30], y.iloc[-30:]

model = xgb.XGBRegressor(
    objective="reg:squarederror",
    n_estimators=500,
    learning_rate=0.05,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    monotone_constraints="(0,0,0,0,0,0,0,0,-1)"
)
model.fit(X_train, y_train)

def forecast_toll_scenario(model, df, vehicle_class=2, change_pct=0.10, horizon=7):
    df_adj = df.copy()
    mask = df_adj["VehicleClass"] == vehicle_class
    df_adj.loc[mask, "TollRate"] *= (1 + change_pct)
    df_adj["Revenue"] = df_adj["Volume"] * df_adj["TollRate"]

    daily_adj = (
        df_adj.groupby(df_adj["Datetime"].dt.date)[["Volume", "Revenue"]].sum().reset_index()
    )
    daily_adj = daily_adj.rename(columns={"Datetime": "Date"})
    daily_adj["Date"] = pd.to_datetime(daily_adj["Date"])
    daily_adj["AvgTollPaid"] = daily_adj["Revenue"] / daily_adj["Volume"]
    daily_adj["DayOfWeek"] = daily_adj["Date"].dt.day_name()
    daily_adj["IsWeekend"] = daily_adj["DayOfWeek"].isin(["Saturday", "Sunday"])

    df_ml = daily_adj.copy()
    df_ml["lag1"] = df_ml["Volume"].shift(1)
    df_ml["lag2"] = df_ml["Volume"].shift(2)
    df_ml["lag7"] = df_ml["Volume"].shift(7)
    df_ml["roll3"] = df_ml["Volume"].shift(1).rolling(3).mean()
    df_ml["roll7"] = df_ml["Volume"].shift(1).rolling(7).mean()
    df_ml["roll14"] = df_ml["Volume"].shift(1).rolling(14).mean()
    df_ml["roll30"] = df_ml["Volume"].shift(1).rolling(30).mean()
    df_ml = df_ml.dropna().reset_index(drop=True)

    feature_cols = ["lag1","lag2","lag7","roll3","roll7","roll14","roll30","IsWeekend","AvgTollPaid"]
    X_adj = df_ml[feature_cols]
    y_pred = model.predict(X_adj.tail(horizon))

    orig_last = daily_df.tail(horizon).reset_index(drop=True)
    new_last  = daily_adj.tail(horizon).reset_index(drop=True)

    results = pd.DataFrame({
        "Date": orig_last["Date"],
        "Prev_Volume": orig_last["Volume"],
        "Prev_Revenue": orig_last["Revenue"],
        "New_Volume": y_pred,
        "New_Revenue": y_pred * new_last["AvgTollPaid"],
        "Diff_Volume": y_pred - orig_last["Volume"],
        "Diff_Revenue": (y_pred * new_last["AvgTollPaid"]) - orig_last["Revenue"]
    })

    return results

scenario_results = forecast_toll_scenario(model, df, vehicle_class=2, change_pct=0.30, horizon=60)
#scenario_results

#Drop the last row of data
scenario_results = scenario_results.iloc[:-1]

total_prev_vol = scenario_results["Prev_Volume"].sum()
total_new_vol  = scenario_results["New_Volume"].sum()
total_prev_rev = scenario_results["Prev_Revenue"].sum()
total_new_rev  = scenario_results["New_Revenue"].sum()

total_vol_change = total_new_vol - total_prev_vol
total_rev_change = total_new_rev - total_prev_rev

pct_vol_change = (total_vol_change / total_prev_vol) * 100
pct_rev_change = (total_rev_change / total_prev_rev) * 100

summary = pd.DataFrame({
    "Total Prev. Vol.": [round(total_prev_vol, 2)],
    "Total New Vol.": [round(total_new_vol, 2)],
    "Total Change in Vol.": [round(total_vol_change, 2)],
    "% Vol. Change": [f"{round(pct_vol_change, 2)}%"],
    "Total Prev. Rev.": [round(total_prev_rev, 2)],
    "Total New Rev.": [round(total_new_rev, 2)],
    "Total Change in Rev.": [round(total_rev_change, 2)],
    "% Rev. Change": [f"{round(pct_rev_change, 2)}%"]
})

summary

#Plot the Changes

#Import the necessary libraries
import numpy as np
import matplotlib.pyplot as plt

def plot_elasticity_curve(model, df_ml, feature_cols, toll_range=(30, 50), steps=50, horizon=60):
    last_days = df_ml.tail(horizon).copy()
    tolls = np.linspace(toll_range[0], toll_range[1], steps)
    all_predictions = []
    for _, row in last_days.iterrows():
        X_base = pd.DataFrame([row[feature_cols].values] * steps, columns=feature_cols)
        X_base["AvgTollPaid"] = tolls
        preds = model.predict(X_base)
        all_predictions.append(preds)
    avg_pred = np.mean(all_predictions, axis=0)

    plt.figure(figsize=(12,5))
    plt.plot(tolls, avg_pred, marker="o")
    plt.title("Elasticity Curve (Avg. over Last 60 Days)")
    plt.xlabel("AvgTollPaid (Toll Rate)")
    plt.ylabel("Predicted Volume")
    plt.grid(True)
    plt.show()

    return pd.DataFrame({"AvgTollPaid": tolls, "Predicted_Volume": avg_pred})

elasticity_results = plot_elasticity_curve(model, df_ml, feature_cols, toll_range=(30, 50), horizon=60)

elasticity_results.head()

